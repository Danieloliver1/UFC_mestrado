{"cells":[{"cell_type":"markdown","metadata":{"id":"g9fJ8l75ABMC"},"source":["Esse dataset é conhecido como Census Income ou Adult dataset, e foi extraído do banco de dados do Censo dos EUA de 1994. O objetivo principal do dataset é prever se uma pessoa ganha mais de 50 mil dólares por ano com base em suas características demográficas e socioeconômicas. Aqui estão os principais detalhes sobre o dataset:\n","Características do Dataset:\n","\n","- Tarefas associadas: Classificação. A tarefa é prever se o rendimento de uma pessoa excede 50 mil dólares por ano.\n","Número de instâncias (linhas): 48.842 pessoas.\n","Número de features (colunas): 14, sendo que algumas são categóricas (como estado civil e ocupação) e outras são numéricas (como idade e horas trabalhadas por semana).\n","Valores ausentes: Algumas colunas têm valores ausentes (exemplo: workclass e occupation).\n","\n","\n","Objetivo:\n","\n","O modelo deve prever se uma pessoa ganha mais de 50 mil dólares anuais (classe >50K) ou menos/igual a isso (classe <=50K), utilizando as 14 características fornecidas.\n","Explicação das Variáveis:\n","\n","age: Idade da pessoa (inteiro).\n","        Tipo: Numérico\n","        Valores ausentes: Não\n","\n","workclass: Categoria de emprego da pessoa (ex.: privado, governo local, etc.).\n","        Tipo: Categórico\n","        Valores ausentes: Sim (alguns registros não têm essa informação)\n","\n","fnlwgt: Peso final da amostra. Este valor indica quantas pessoas na população original são representadas por essa instância.\n","        Tipo: Numérico\n","        Valores ausentes: Não\n","\n","education: Nível de educação da pessoa (ex.: bacharelado, ensino médio, etc.).\n","        Tipo: Categórico\n","        Valores ausentes: Não\n","\n","education-num: Nível de escolaridade representado por um número (1-16).\n","        Tipo: Numérico\n","        Valores ausentes: Não\n","\n","marital-status: Estado civil (ex.: casado, divorciado, solteiro, etc.).\n","        Tipo: Categórico\n","        Valores ausentes: Não\n","\n","occupation: Tipo de ocupação (ex.: gerência executiva, vendas, suporte técnico, etc.).\n","        Tipo: Categórico\n","        Valores ausentes: Sim\n","\n","relationship: Papel dentro da família (ex.: esposa, marido, filho, etc.).\n","        Tipo: Categórico\n","        Valores ausentes: Não\n","\n","race: Raça (ex.: branca, asiática, negra, etc.).\n","        Tipo: Categórico\n","        Valores ausentes: Não\n","\n","sex: Gênero (feminino ou masculino).\n","        Tipo: Binário\n","        Valores ausentes: Não\n","\n","capital-gain: Ganho de capital (numérico).\n","        Tipo: Numérico\n","        Valores ausentes: Não\n","\n","capital-loss: Perda de capital (numérico).\n","        Tipo: Numérico\n","        Valores ausentes: Não\n","\n","hours-per-week: Horas trabalhadas por semana.\n","        Tipo: Numérico\n","        Valores ausentes: Não\n","\n","native-country: País de origem (ex.: Estados Unidos, Canadá, etc.).\n","        Tipo: Categórico\n","        Valores ausentes: Sim\n","\n","Pontos Importantes:\n","\n","- Valores ausentes: Algumas variáveis como workclass, occupation, e native-country têm valores ausentes, o que exige tratamento na preparação dos dados.\n","Problema de classificação: A variável de saída (target) é se a pessoa ganha mais de 50K (>50K) ou menos/igual a 50K (<=50K).\n","Características categóricas e numéricas: Algumas variáveis são categóricas, o que requer técnicas como one-hot encoding para usá-las em algoritmos de aprendizado de máquina.\n","\n","Aplicações:\n","\n","- Esse dataset é usado para construir modelos preditivos de classificação, onde as variáveis são usadas para prever a classe de rendimento (>50K ou <=50K). Ele é amplamente utilizado em tutoriais e estudos de classificação em machine learning."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"bGmcHYU41jlK","executionInfo":{"status":"ok","timestamp":1727456489784,"user_tz":180,"elapsed":376,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"o2AKM7TKR5_j","executionInfo":{"status":"ok","timestamp":1727456490886,"user_tz":180,"elapsed":18,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"outputs":[],"source":["#!pip install aequitas"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"GzBq3TO_R8c7","executionInfo":{"status":"ok","timestamp":1727456490886,"user_tz":180,"elapsed":17,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"outputs":[],"source":["#!pip install keras-tuner"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1727456490887,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"},"user_tz":180},"id":"EBgL5otK2S5H"},"outputs":[],"source":["# Importações de bibliotecas necessárias para o tratamento de dados\n","import math\n","import pandas as pd\n","import numpy as np\n","\n","# Importações de bibliotecas para manipulação de dados e modelos\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle # Embaralhar os dados\n","\n","# Normalização de dados\n","from sklearn.preprocessing import OneHotEncoder # Converte categorias em colunas binárias (0 ou 1)\n","from sklearn.preprocessing import LabelEncoder   # Converte categorias em números\n","from sklearn.preprocessing import StandardScaler # Normalização usando Z-score\n","\n","# Importações para estatísticas e testes estatísticos\n","from statsmodels.stats.proportion import proportions_ztest\n","from scipy.stats import norm\n","\n","# Métricas de avaliação de modelos\n","from sklearn.metrics import accuracy_score, classification_report,accuracy_score\n","from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n","\n","\n","# Modelos de machine learning do scikit-learn\n","from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","\n","# Importações de bibliotecas para redes neurais usando TensorFlow/Keras\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape, Flatten\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import layers, Input\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras import regularizers\n","import keras_tuner as kt\n","\n","\n","\n","\n","\n","# Bibliotecas para gráficos\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from aequitas import Audit\n","from aequitas.plotting import Plot\n","from aequitas.group import Group\n","from aequitas.audit import Audit\n"]},{"cell_type":"markdown","metadata":{"id":"_K2dSSzW7L-0"},"source":["# **Tratamento de dados**"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"yfG2qhRp-g1H","executionInfo":{"status":"ok","timestamp":1727456490887,"user_tz":180,"elapsed":16,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"outputs":[],"source":["def grafico_matriz_confusao(conf_matrix,accuracy, titulo):\n","\n","    conf_matrix_percentage = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis] * 100\n","\n","    # Função para adicionar o símbolo de porcentagem aos valores na matriz de confusão\n","    labels = [f'{value:.2f}%' for value in conf_matrix_percentage.flatten()]\n","    labels = np.array(labels).reshape(conf_matrix.shape)\n","\n","    # Converter a acurácia para porcentagem\n","    accuracy_percentage = accuracy * 100\n","\n","    # Plot da matriz de confusão com porcentagens e a acurácia em porcentagem\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(conf_matrix_percentage, annot=labels, fmt='', cmap='Blues', cbar=False, annot_kws={\"size\": 16})\n","    plt.title(f'Matriz de Confusão (Porcentagem)\\n{titulo}\\nAcurácia: {accuracy_percentage:.2f}%', size=16)\n","    plt.xlabel('Predição', size=14)\n","    plt.ylabel('Real', size=14)\n","    return plt.show()\n","\n","\n","\n","def grafico_curva_roc(fpr, tpr,roc_auc, titulo):\n","    # Plot da curva ROC\n","\n","    plt.figure()\n","    plt.plot(fpr, tpr, color='blue', lw=2, label='Curva ROC (área = %0.2f)' % roc_auc)\n","    plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Taxa de Falsos Positivos')\n","    plt.ylabel('Taxa de Verdadeiros Positivos')\n","    plt.title(f'Curva ROC {titulo}')\n","    plt.legend(loc=\"lower right\")\n","    print(f\"ROC AUC: {roc_auc}\")\n","    return plt.show()\n","\n","def grafico_metricas_sensiveis(y_pred):\n","    # Preparar o DataFrame para o Aequitas\n","    aequitas_df = test_data_adult[['sex', 'race']].copy()\n","    aequitas_df['label'] = test_data_adult['income']  # Renomeia a coluna de rótulo para 'label_value'\n","    aequitas_df['score'] = y_pred  # Adiciona as previsões do modelo\n","\n","    # Inicializando o Audit sem passar o DataFrame\n","    audit = Audit(aequitas_df)\n","\n","    # Gera o gráfico de summary_plot para as métricas desejadas\n","    audit.audit()\n","    return audit.summary_plot([\"tpr\", \"fpr\", \"pprev\"])\n"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1727456490887,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"},"user_tz":180},"id":"tRMMv0acSQfL"},"outputs":[],"source":["# # train_url = '/content/adult.data'\n","# train_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n","# link_index = '/content/Index'\n","\n","# test_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\"\n","\n","# # link_informacoes = '/content/adult.names'\n","# link_informacoes = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names'\n","# # test_url = '/content/adult.test'\n","\n","# # Nome das colunas do dataset\n","# column_names = [\n","#     'age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n","#     'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n","#     'hours-per-week', 'native-country', 'income'\n","# ]\n","\n","# test_data_adult = pd.read_csv(test_url, header=0, names=column_names, na_values=\" ?\", sep=',\\s', engine='python')\n","# train_data_adult = pd.read_csv(train_url, header=None, names=column_names, na_values=\" ?\", sep=',\\s', engine='python')"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1727456490889,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"},"user_tz":180},"id":"dZIhF_JbSev1"},"outputs":[],"source":["# # Substituir strings vazias por NaN e remover linhas com valores nulos\n","# train_data_adult.dropna(inplace=True)\n","# test_data_adult.dropna(inplace=True)\n","\n","\n","# # Codificar a variável alvo ('income') transformando em binarios\n","# train_data_adult['income'] = train_data_adult['income'].apply(lambda x: 1 if x == '>50K' else 0)\n","# test_data_adult['income'] = test_data_adult['income'].apply(lambda x: 1 if x == '>50K.' else 0)\n","\n","# # Codificar a variável sex transformando em binarios\n","# train_data_adult['sex'] = train_data_adult['sex'].apply(lambda x: 1 if x == 'Male' else 0)\n","# test_data_adult['sex'] = test_data_adult['sex'].apply(lambda x: 1 if x == 'Male' else 0)\n","# # Codificação de variáveis categóricas para binarios\n","# categorical_cols = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country']\n","\n","# for col in categorical_cols:\n","#     label_encoder = LabelEncoder()\n","#     train_data_adult[col] = label_encoder.fit_transform(train_data_adult[col])\n","#     test_data_adult[col] = label_encoder.transform(test_data_adult[col])\n","\n","# # scaler = StandardScaler()\n","# # encoded_train_features = scaler.fit_transform(train_data_adult[categorical_cols])\n","# # encoded_test_features = scaler.transform(test_data_adult[categorical_cols])"]},{"cell_type":"code","source":["# train_data_adult"],"metadata":{"id":"00STfhGdwYkj","executionInfo":{"status":"ok","timestamp":1727456490889,"user_tz":180,"elapsed":15,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1727456490889,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"},"user_tz":180},"id":"yuVxw6gi7YqT"},"outputs":[],"source":["# # excluindo dados\n","# # Substituir strings vazias por NaN\n","# train_data_adult.replace('', np.nan, inplace=True)\n","\n","# # Remover linhas com valores nulos\n","# train_data_adult_cleaned = train_data_adult.dropna()"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1727456490889,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"},"user_tz":180},"id":"qfaBIuNvS-CB"},"outputs":[],"source":["# dados_sensiveis_train = pd.DataFrame()\n","\n","# dados_sensiveis_train['Amer-Indian-Eskimo'] = train_data_adult.iloc[:,8].apply(lambda x: 1 if x == 'Amer-Indian-Eskimo' else 0)\n","# dados_sensiveis_train['Asian-Pac-Islander'] = train_data_adult.iloc[:,8].apply(lambda x: 1 if x == 'Asian-Pac-Islander' else 0)\n","# dados_sensiveis_train['Black'] = train_data_adult.iloc[:,8].apply(lambda x: 1 if x == 'Black' else 0)\n","# dados_sensiveis_train['Other'] = train_data_adult.iloc[:,8].apply(lambda x: 1 if x == 'Other' else 0)\n","# dados_sensiveis_train['White'] = train_data_adult.iloc[:,8].apply(lambda x: 1 if x == 'White' else 0)\n","# dados_sensiveis_train['Genero'] = train_data_adult.iloc[:,9].apply(lambda x: 1 if x == 'Male' else 0)\n","\n","# dados_sensiveis_train['income_binary'] = train_data_adult.iloc[:,-1]"]},{"cell_type":"code","source":["# dados_sensiveis_test = pd.DataFrame()\n","\n","# dados_sensiveis_test['Amer-Indian-Eskimo'] = test_data_adult.iloc[:,8].apply(lambda x: 1 if x == 'Amer-Indian-Eskimo' else 0)\n","# dados_sensiveis_test['Asian-Pac-Islander'] = test_data_adult.iloc[:,8].apply(lambda x: 1 if x == 'Asian-Pac-Islander' else 0)\n","# dados_sensiveis_test['Black'] = test_data_adult.iloc[:,8].apply(lambda x: 1 if x == 'Black' else 0)\n","# dados_sensiveis_test['Other'] = test_data_adult.iloc[:,8].apply(lambda x: 1 if x == 'Other' else 0)\n","# dados_sensiveis_test['White'] = test_data_adult.iloc[:,8].apply(lambda x: 1 if x == 'White' else 0)\n","# dados_sensiveis_test['Genero'] = test_data_adult.iloc[:,9].apply(lambda x: 1 if x == 'Male' else 0)\n","\n","# dados_sensiveis_test['income_binary'] = test_data_adult.iloc[:,-1]"],"metadata":{"id":"HGDoKYarPqg1","executionInfo":{"status":"ok","timestamp":1727456490889,"user_tz":180,"elapsed":13,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# # Excluindo a coluna 'B'\n","# train_data_adult = train_data_adult.drop('race', axis=1)\n","# #train_data_adult = train_data_adult.drop('B', axis=1)\n","# test_data_adult = test_data_adult.drop('race', axis=1)\n","# #test_data_adult = test_data_adult.drop('B', axis=1)"],"metadata":{"id":"yzeyYZt5QLXc","executionInfo":{"status":"ok","timestamp":1727456490889,"user_tz":180,"elapsed":12,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["\n","# # Concatenação das colunas codificadas com as numéricas\n","# numeric_cols = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n","# X_train = pd.concat([dados_sensiveis_train, train_data_adult[numeric_cols].reset_index(drop=True)], axis=1)\n","# X_test = pd.concat([dados_sensiveis_test, test_data_adult[numeric_cols].reset_index(drop=True)], axis=1)\n","\n","# # Converter os nomes das colunas para strings\n","# X_train.columns = X_train.columns.astype(str)\n","# X_test.columns = X_test.columns.astype(str)\n","\n","# # Variável alvo\n","# y_train = train_data_adult['income']\n","# y_test = test_data_adult['income']\n","\n","# # Dividir o conjunto de treinamento em treino e validação\n","# # X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n","\n","\n","\n","# #______________________________________________________________\n","# from imblearn.over_sampling import SMOTE\n","\n","# smote = SMOTE()\n","\n","\n","# # Rebalanceamento\n","# X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n","\n","# # Dividir o conjunto de treinamento em treino e validação\n","# X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n","\n","\n","# #______________________________________________________________\n","\n","# # Padronizar as variáveis numéricas\n","# scaler = StandardScaler()\n","# X_train = scaler.fit_transform(X_train)\n","# X_val = scaler.transform(X_val)\n","# X_test = scaler.transform(X_test)"],"metadata":{"id":"U1WAQLC8RPrA","executionInfo":{"status":"ok","timestamp":1727456490889,"user_tz":180,"elapsed":12,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kglRPxBfy7tq","executionInfo":{"status":"ok","timestamp":1727456490889,"user_tz":180,"elapsed":12,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","execution_count":25,"metadata":{"id":"CIEHZXDQ9w9O","executionInfo":{"status":"ok","timestamp":1727456496591,"user_tz":180,"elapsed":5713,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"outputs":[],"source":["# # URLs dos datasets de treinamento e teste\n","train_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n","test_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\"\n","\n","# Nome das colunas do dataset\n","column_names = [\n","    'age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n","    'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n","    'hours-per-week', 'native-country', 'income'\n","]\n","\n","# Carregar os dados\n","train_data_adult = pd.read_csv(train_url, header=None, names=column_names, na_values=\" ?\", sep=',\\s', engine='python')\n","test_data_adult = pd.read_csv(test_url, header=0, names=column_names, na_values=\" ?\", sep=',\\s', engine='python')\n","\n","train_data_adult.dropna(inplace=True)\n","test_data_adult.dropna(inplace=True)\n","\n","# Codificar a variável alvo ('income')\n","train_data_adult['income'] = train_data_adult['income'].apply(lambda x: 1 if x.strip() == '>50K' else 0)\n","test_data_adult['income'] = test_data_adult['income'].apply(lambda x: 1 if x.strip() == '>50K.' else 0)\n","\n","# Codificação das variáveis categóricas\n","categorical_cols = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n","encoder = OneHotEncoder(drop='first', sparse_output=False)\n","encoded_train_features = encoder.fit_transform(train_data_adult[categorical_cols])\n","encoded_test_features = encoder.transform(test_data_adult[categorical_cols])\n","\n","\n","\n","# Concatenação das colunas codificadas com as numéricas\n","numeric_cols = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n","X_train = pd.concat([pd.DataFrame(encoded_train_features), train_data_adult[numeric_cols].reset_index(drop=True)], axis=1)\n","X_test = pd.concat([pd.DataFrame(encoded_test_features), test_data_adult[numeric_cols].reset_index(drop=True)], axis=1)\n","\n","# Converter os nomes das colunas para strings\n","X_train.columns = X_train.columns.astype(str)\n","X_test.columns = X_test.columns.astype(str)\n","\n","# Variável alvo\n","y_train = train_data_adult['income']\n","y_test = test_data_adult['income']\n","\n","# Dividir o conjunto de treinamento em treino e validação\n","# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n","\n","\n","\n","#______________________________________________________________\n","from imblearn.over_sampling import SMOTE\n","\n","smote = SMOTE()\n","\n","\n","# Rebalanceamento\n","X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n","\n","# Dividir o conjunto de treinamento em treino e validação\n","X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n","\n","\n","#______________________________________________________________\n","\n","# Padronizar as variáveis numéricas\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","X_test = scaler.transform(X_test)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"QYhhjqP89yy_","executionInfo":{"status":"ok","timestamp":1727456496596,"user_tz":180,"elapsed":49,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"outputs":[],"source":["# # O autoencoder é uma arquitetura de rede neural usada principalmente para aprendizado não supervisionado e compressão de dados,\n","# # onde o objetivo é aprender uma representação comprimida (codificada) dos dados de entrada e, em seguida, reconstruir os dados originais.\n","\n","# def build_autoencoder(hp):\n","#     input_shape = 100\n","\n","#     input_layer = layers.Input(shape=(input_shape,))\n","#     encoded = layers.Dense(hp.Int('units1', min_value=32, max_value=128, step=32), activation='relu')(input_layer)\n","#     encoded = layers.Dense(hp.Int('units2', min_value=16, max_value=64, step=16), activation='relu')(encoded)\n","\n","#     decoded = layers.Dense(hp.Int('units3', min_value=32, max_value=128, step=32), activation='relu')(encoded)\n","#     decoded = layers.Dense(input_shape, activation='sigmoid')(decoded)\n","\n","#     autoencoder = tf.keras.Model(inputs=input_layer, outputs=decoded)\n","#     autoencoder.compile(optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate', 1e-4, 1e-2, sampling='LOG')), loss='mse')\n","#     return autoencoder\n","\n","# def tune_autoencoder(x_train):\n","#     tuner = kt.Hyperband(\n","#         build_autoencoder,\n","#         objective='val_loss',\n","#         max_epochs=20,\n","#         factor=3,\n","#         directory='autoencoder_tuning',\n","#         project_name='autoencoder'\n","#     )\n","\n","#     tuner.search(X_train, X_train, epochs=10, validation_split=0.2)\n","#     best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","#     # Print hyperparameters in a more readable format\n","#     print(\"Best hyperparameters:\")\n","#     print(f\"Units in the first layer: {best_hps.get('units1')}\")\n","#     print(f\"Units in the second layer: {best_hps.get('units2')}\")\n","#     print(f\"Units in the third layer: {best_hps.get('units3')}\")\n","#     print(f\"Learning rate: {best_hps.get('learning_rate')}\")\n","\n","#     return best_hps\n","\n","\n","# tune_autoencoder(X_train)"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":38,"status":"ok","timestamp":1727456496596,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"},"user_tz":180},"id":"eulOVqIl-GAw"},"outputs":[],"source":["# best_hps = tune_autoencoder(X_train)"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":35,"status":"ok","timestamp":1727456496597,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"},"user_tz":180},"id":"37-7dfR590C8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c0a9da89-ccc3-4906-eb38-e363fb5d240c"},"outputs":[{"output_type":"stream","name":"stdout","text":["(49440, 100) (49440,)\n"]}],"source":["# Verifique as formas após o SMOTE\n","print(X_resampled.shape, y_resampled.shape)\n"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1727456496597,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"},"user_tz":180},"id":"jkymDUEa92pd"},"outputs":[],"source":["# Definir a arquitetura do Autoencoder\n","input_shape = X_train.shape[1]\n","\n","def build_autoencoder(input_shape, units1, units2, units3, learning_rate):\n","    input_layer = tf.keras.layers.Input(shape=(input_shape,))\n","    encoded = tf.keras.layers.Dense(units1, activation='relu')(input_layer)\n","    encoded = tf.keras.layers.Dense(units2, activation='relu')(encoded)\n","    decoded = tf.keras.layers.Dense(units3, activation='relu')(encoded)\n","    decoded = tf.keras.layers.Dense(input_shape, activation='sigmoid')(decoded)\n","\n","    autoencoder = tf.keras.Model(inputs=input_layer, outputs=decoded)\n","    autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mse')\n","    return autoencoder\n"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"elapsed":436,"status":"error","timestamp":1727456497008,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"},"user_tz":180},"id":"kQXd1i8b-IMF","outputId":"21fdd370-ae40-466d-b08f-59ec9f6b039c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n"]},{"output_type":"error","ename":"ValueError","evalue":"Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 13), found shape=(128, 100)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-f391eb9344e5>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Treinamento com pesos de classe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m autoencoder.fit(X_train, X_train, epochs=50, batch_size=128, shuffle=True,\n\u001b[0m\u001b[1;32m     20\u001b[0m                 validation_data=(X_val, X_val))\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                         raise ValueError(\n\u001b[0m\u001b[1;32m    246\u001b[0m                             \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                             \u001b[0;34m\"incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 13), found shape=(128, 100)"]}],"source":["# Treinamento do Autoencoder\n","# Classificação Baseada em Custo\n","# Para ajustar o peso das classes em redes neurais, você pode usar o argumento class_weight durante o treinamento.\n","# Isso penaliza mais os erros nas classes minoritárias. Aqui está um exemplo básico usando o Keras:\n","\n","# Instanciando o autoencoder\n","# autoencoder = build_autoencoder(\n","#     input_shape=input_shape,\n","#     units1=best_hps.get('units1'),  # Aqui você estava repetindo `input_shape` por engano\n","#     units2=best_hps.get('units2'),\n","#     units3=best_hps.get('units3'),\n","#     learning_rate=best_hps.get('learning_rate')\n","# )\n","\n","\n","autoencoder = build_autoencoder(13,  96,   48,  96,   0.00012225501914742633)\n","\n","# Treinamento com pesos de classe\n","autoencoder.fit(X_train, X_train, epochs=50, batch_size=128, shuffle=True,\n","                validation_data=(X_val, X_val))\n","\n"]},{"cell_type":"code","source":["X_val.shape"],"metadata":{"id":"-Mz_dz2f1GdM","executionInfo":{"status":"aborted","timestamp":1727456497009,"user_tz":180,"elapsed":39,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.shape"],"metadata":{"id":"EJoZgjaT1KI8","executionInfo":{"status":"aborted","timestamp":1727456497009,"user_tz":180,"elapsed":37,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":33,"status":"aborted","timestamp":1727456497009,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"},"user_tz":180},"id":"B7mvEmra-KLG"},"outputs":[],"source":["# a codificação do autoencoder é usada para obter uma representação reduzida dos dados de entrada.\n","X_train_encoded = autoencoder.predict(X_train)\n","X_val_encoded = autoencoder.predict(X_val)\n","X_test_encoded = autoencoder.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":32,"status":"aborted","timestamp":1727456497010,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"},"user_tz":180},"id":"7EoDKtYi-Lsd"},"outputs":[],"source":["# Projetada para construir um classificador com hiperparâmetros ajustáveis, que são fornecidos pelo objeto hp (HyperParameters).\n","# Isso é usado em conjunto com o Keras Tuner para realizar uma busca automatizada pelos melhores hiperparâmetros para o modelo.\n","def build_classifier(hp):\n","    input_shape = X_train.shape[1]\n","\n","    input_layer = tf.keras.layers.Input(shape=(input_shape,))\n","\n","    # Hiperparâmetros para o número de unidades nas camadas ocultas\n","    units1 = hp.Int('units1', min_value=32, max_value=128, step=32)\n","    units2 = hp.Int('units2', min_value=16, max_value=64, step=16)\n","\n","    # Hiperparâmetro para a taxa de dropout\n","    dropout_rate = hp.Float('dropout_rate', min_value=0.3, max_value=0.7, step=0.1)\n","\n","    hidden = tf.keras.layers.Dense(units1, activation='relu',\n","                                   kernel_regularizer=regularizers.l2(0.001))(input_layer)\n","    hidden = tf.keras.layers.Dropout(dropout_rate)(hidden)\n","    hidden = tf.keras.layers.Dense(units2, activation='relu',\n","                                   kernel_regularizer=regularizers.l2(0.001))(hidden)\n","    output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(hidden)\n","\n","    classifier = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n","    classifier.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n","    return classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":31,"status":"aborted","timestamp":1727456497010,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"},"user_tz":180},"id":"7fmMv2Y3-Np1"},"outputs":[],"source":["#  Keras Tuner para realizar a busca por hiperparâmetros e encontrar a melhor\n","# configuração para o classificador definido pela função build_classifier\n","def tune_classifier(x_train, y_train):\n","    tuner = kt.Hyperband(\n","        build_classifier,\n","        objective='val_accuracy',\n","        max_epochs=20,\n","        factor=3,\n","        directory='classifier_tuning',\n","        project_name='classifier'\n","    )\n","\n","    tuner.search(x_train, y_train, epochs=20, validation_split=0.2)\n","    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","\n","    return best_hps\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D6l9j6u6-RMI","executionInfo":{"status":"aborted","timestamp":1727456497011,"user_tz":180,"elapsed":30,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"outputs":[],"source":["best_hps = tune_classifier(X_train, y_train)\n","\n","\n","# Imprimir os melhores hiperparâmetros\n","print(\"Melhores Hiperparâmetros Encontrados:\")\n","print(best_hps)\n","\n","# Aplicar os melhores hiperparâmetros encontrados\n","input_shape = X_train.shape[1]\n","classifier = build_classifier(best_hps)\n","\n","# Early Stopping\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","# Treinar o modelo com os melhores hiperparâmetros\n","# history = classifier.fit(X_train, y_train, epochs=20, validation_split=0.2)\n","history_classifier = classifier.fit(X_train_encoded, y_train, epochs=20, batch_size=128, validation_data=(X_val_encoded, y_val), callbacks=[early_stopping])"]},{"cell_type":"code","source":["y_pred_income = autoencoder.predict(X_test_encoded)\n","y_pred_income = (y_pred_income > 0.5).astype(int)\n","np.unique(y_pred_income)"],"metadata":{"id":"jAoNFu4MveRn","executionInfo":{"status":"aborted","timestamp":1727456497011,"user_tz":180,"elapsed":29,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test_encoded.shape"],"metadata":{"id":"sKQ3BdjY6cN4","executionInfo":{"status":"aborted","timestamp":1727456497011,"user_tz":180,"elapsed":28,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test.shape"],"metadata":{"id":"cUoZW_T_6fu-","executionInfo":{"status":"aborted","timestamp":1727456497012,"user_tz":180,"elapsed":28,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ogSDM24A-Ume","executionInfo":{"status":"aborted","timestamp":1727456497012,"user_tz":180,"elapsed":27,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"outputs":[],"source":["# Previsão do classificador no conjunto de teste\n","\n","#y_pred_income = autoencoder.predict(X_test_encoded)\n","y_pred_income = classifier.predict(X_test_encoded)\n","y_pred_income = (y_pred_income > 0.5).astype(int).reshape(-1,1)\n","\n","# Avaliação do classificador para prever 'income'\n","conf_matrix_income = confusion_matrix(y_test, y_pred_income)\n","\n","# Calcular porcentagens\n","conf_matrix_percentage = conf_matrix_income.astype('float') / conf_matrix_income.sum(axis=1)[:, np.newaxis] * 100\n","labels = [f\"{value:.2f}%\" for value in conf_matrix_percentage.flatten()]\n","labels = np.array(labels).reshape(conf_matrix_income.shape)\n","\n","# Calcular a Curva ROC\n","fpr, tpr, _ = roc_curve(y_test, classifier.predict(X_test_encoded))\n","roc_auc = roc_auc_score(y_test, classifier.predict(X_test_encoded))\n","\n","\n","# Acurácia (em porcentagem)\n","accuracy_income = accuracy_score(y_test, y_pred_income)\n","accuracy_income"]},{"cell_type":"code","source":["\n","print(classification_report(y_test, y_pred_income))"],"metadata":{"id":"Cbz9UWUmay3f","executionInfo":{"status":"aborted","timestamp":1727456497013,"user_tz":180,"elapsed":27,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # URLs dos datasets de treinamento e teste\n","train_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n","test_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\"\n","\n","# Nome das colunas do dataset\n","column_names = [\n","    'age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n","    'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n","    'hours-per-week', 'native-country', 'income'\n","]\n","\n","# Carregar os dados\n","train_data_adult = pd.read_csv(train_url, header=None, names=column_names, na_values=\" ?\", sep=',\\s', engine='python')\n","test_data_adult = pd.read_csv(test_url, header=0, names=column_names, na_values=\" ?\", sep=',\\s', engine='python')\n","\n","train_data_adult.dropna(inplace=True)\n","test_data_adult.dropna(inplace=True)\n","\n","# Codificar a variável alvo ('income')\n","#train_data_adult['income'] = train_data_adult['income'].apply(lambda x: 1 if x.strip() == '>50K' else 0)\n","test_data_adult['income'] = test_data_adult['income'].apply(lambda x: 1 if x.strip() == '>50K.' else 0)\n","\n","\n","def grafico_metricas_sensiveis(y_pred):\n","    # Preparar o DataFrame para o Aequitas\n","    aequitas_df = test_data_adult[['sex', 'race']].copy()\n","    aequitas_df['label'] = test_data_adult['income']  # Renomeia a coluna de rótulo para 'label_value'\n","    aequitas_df['score'] = y_pred  # Adiciona as previsões do modelo\n","\n","    # Inicializando o Audit sem passar o DataFrame\n","    audit = Audit(aequitas_df)\n","\n","    # Gera o gráfico de summary_plot para as métricas desejadas\n","    audit.audit()\n","    return audit.summary_plot([\"tpr\", \"fpr\", \"pprev\"])"],"metadata":{"id":"kc8PQ32I66Te","executionInfo":{"status":"aborted","timestamp":1727456497013,"user_tz":180,"elapsed":25,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NF8W2sTC-WhG","executionInfo":{"status":"aborted","timestamp":1727456497013,"user_tz":180,"elapsed":21,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"outputs":[],"source":["grafico_metricas_sensiveis(y_pred_income)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F26Peilu-Y94","executionInfo":{"status":"aborted","timestamp":1727456497014,"user_tz":180,"elapsed":21,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"outputs":[],"source":["#grafico_matriz_confusao(conf_matrix_income,accuracy_income,'Modelo FAN')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3sk3Zrpw-bOW","executionInfo":{"status":"aborted","timestamp":1727456497014,"user_tz":180,"elapsed":20,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"outputs":[],"source":["# Plotar a curva de loss (erro)\n","# plt.plot(history_classifier.history['loss'], label='Loss Treinamento')\n","# plt.plot(history_classifier.history['val_loss'], label='Loss Validação')\n","# plt.title('Curva de Loss do Classificador')\n","# plt.xlabel('Épocas')\n","# plt.ylabel('Loss')\n","# plt.legend()\n","# plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B19OEc3X-eOs","executionInfo":{"status":"aborted","timestamp":1727456497014,"user_tz":180,"elapsed":19,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"outputs":[],"source":["# # Salvar o autoencoder no formato nativo Keras\n","# autoencoder.save('autoencoder_model.keras')\n","\n","# # Salvar o classificador no formato nativo Keras\n","# classifier.save('classifier_model.keras')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vNmrNSyN-lLn","executionInfo":{"status":"aborted","timestamp":1727456497014,"user_tz":180,"elapsed":19,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"outputs":[],"source":["# # Carregar o autoencoder\n","# autoencoder_loaded = load_model('/content/autoencoder_model.keras')\n","\n","# # Carregar o classificador\n","# classifier_loaded = load_model('/content/classifier_model.keras')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pKpfLNVy-mrn","executionInfo":{"status":"aborted","timestamp":1727456497015,"user_tz":180,"elapsed":19,"user":{"displayName":"Daniel_Programador Alura","userId":"15916621156725092465"}}},"outputs":[],"source":["# # Previsão com o autoencoder carregado\n","# X_test_encoded = autoencoder_loaded.predict(X_test)\n","\n","# # Previsão com o classificador carregado\n","# y_pred_income = classifier_loaded.predict(X_test_encoded)\n","# y_pred_income = (y_pred_income > 0.5).astype(int)\n","\n","# # Avaliação do classificador\n","# accuracy_income = accuracy_score(y_test, y_pred_income) * 100\n","# print(f'Acurácia: {accuracy_income:.2f}%')\n","\n","\n","# # history_classifier = classifier_loaded.fit(X_train_encoded, y_train, epochs=10, batch_size=128,\n","# #                                            validation_data=(X_val_encoded, y_val))"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMXWMIYYxxIZJe75kT5UcT2"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}